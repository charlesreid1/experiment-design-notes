{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness of Fit Metrics\n",
    "\n",
    "Link: [http://charlesreid1.com/wiki/Response_Surface_Methodology](http://charlesreid1.com/wiki/Response_Surface_Methodology)\n",
    "\n",
    "## Analysis of Variance (ANOVA Table)\n",
    "\n",
    "ANOVA is a statistical technique that builds a table attributing the variance in the system response to various degrees of freedom. Each piece of data about the real system contributes one degree of freedom, which can go toward estimating a new coefficient, or can go toward estimating the variance in the model.\n",
    "\n",
    "Bibliography note: Mason ch. 6, 8 - derived in 6.1\n",
    "\n",
    "For ANOVA of linear regression models, need to define a few quantities.\n",
    "\n",
    "Total sum of squares: \n",
    "\n",
    "$$\n",
    "TSS = \\sum \\left( y_i - \\overline{y} \\right)^2\n",
    "$$\n",
    "\n",
    "Error sum of squares:\n",
    "\n",
    "$$\n",
    "SSE = \\sum \\left( y_i - \\hat{y}_i \\right)^2\n",
    "$$\n",
    "\n",
    "Model sum of squares (regression sum of squares):\n",
    "\n",
    "$$\n",
    "SSR = \\sum \\left( \\hat{y}_i - \\overline{y} \\right)^2\n",
    "$$\n",
    "\n",
    "### Univariate Linear Model\n",
    "\n",
    "(Sample ANOVA table constructed for a linear univariate function)\n",
    "\n",
    "### Multiple Linear Model\n",
    "\n",
    "Important not just to assess overall fit of prediction equation\n",
    "\n",
    "Also important to assess contribution of individual predictor variables to the fit\n",
    "\n",
    "Many commonly-reported measures of model fitness are part of ANOVA table\n",
    "\n",
    "Multivariate models: p degrees of freedom for sum of squares due to regression (because p coefficients {\\beta_1, \\beta_2, \\dots \\beta_p} must be estimated to obtain regression sum of squares\n",
    "\n",
    "(Sample ANOVA table constructed for multiple linear function)\n",
    "\n",
    "\n",
    "\n",
    "$p$ is number of predictor variables. To measure the adequacy of fitted model, determine the error standard deviation:\n",
    "\n",
    "$$\n",
    "s_e = (MSE)^{1/2}\n",
    "$$\n",
    "\n",
    "where $MSE = SSE/(n-p-1)$.\n",
    "\n",
    "Small $s_e$ means predicted responses closely approximate observed responses.\n",
    "\n",
    "Large $s_e$ means large random error, or poor selection of model form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-Statistic\n",
    "\n",
    "Main article: F-Statistic\n",
    "\n",
    "I found this short YouTube video very helpful for illustrating what the F-statistic means physically: [link](http://www.youtube.com/watch?v=TMwSS8DAVYk)\n",
    "\n",
    "The F-statistic can be thought of as a frequentist metric for hypothesis-testing. Once an F-statistic and corresponding p-value is calculated from the ANOVA table quantities, you can determine how confident you can be in a given hypothesis test (where the hypothesis is the model onto which you've chosen to regress your data).\n",
    "\n",
    "Mason: Different from tests for significance of factor effects in analysis of designed experiments\n",
    "\n",
    "Mason: example of acid-content data...\n",
    "\n",
    "For multiple linear regression/model, can use F-statistic to simultaneously test a hypothesis: whether all $\\beta_j = 0$ (the hypothesis), or whether at least one $\\beta_j \\neq 0$ (the null hypothesis, i.e., the outcome that our hypothesis is not correct).\n",
    "\n",
    "$\\beta_1 = \\beta_2 = \\dots = \\beta_p = 0$ versus $\\beta_j \\neq 0$\n",
    "\n",
    "(While this seems silly, it's much more useful if you're doing this for a subset of coefficients - such as testing the hypothesis of whether any of a subset of coefficients should be non-zero.)\n",
    "\n",
    "### Lack of Fit F-Statistic\n",
    "\n",
    "For (deterministic) computer simulations (rather than experiments, which have random error), error is entirely due to lack of fit - there is no source of random error from real instruments or real experimental noise.\n",
    "\n",
    "In this case, an F-statistic specifically for lack-of-fit is not possible to calculate (defined as $MSE_{LOF}/MSE_{P}$, and $MSE_P = 0 $for deterministic functions)\n",
    "\n",
    "### Partial F-Test (Determination of Term Significance)\n",
    "\n",
    "Consider a full regresion model with $p$ predictor variables.\n",
    "\n",
    "Now consider a reduced regression model with $k < p$ predictor variables.\n",
    "\n",
    "Full model = $M_1$\n",
    "\n",
    "Reduced model = $M_2$\n",
    "\n",
    "Reduction in error sum of squares resulting from fit of additional terms in full model:\n",
    "\n",
    "$$\n",
    "R(M_1 \\vert M_2) = SSE_2 - SSE_1\n",
    "$$\n",
    "\n",
    "$(p - k)$ more predictor variables\n",
    "\n",
    "F-statistic for determining statistical significance of this subset is:\n",
    "\n",
    "$$\n",
    "F = \\frac{ MSR(M_1 \\vert M_2) }{ MSE_1 }\n",
    "$$\n",
    "\n",
    "where $MSR(M_1 \\vert M_2) = \\frac{ R(M_1 \\vert M_2) }{ (p-k) }$\n",
    "\n",
    "If $k = p-1$ then the F-statistic is the square of the t-statistic from the full model corresponding to the term left out of the reduced model\n",
    "\n",
    "To determine if F-statistic is highly significant, use p value (95% likelihood of being significant if $p < 0.05$, 99% likelihood if $p < 0.01$)\n",
    "\n",
    "Example: use to determine if interaction effect is important to surrogate model.\n",
    "\n",
    "Using this procedure and using the t-statistic to test the significance of a given term are equivalent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Statistic\n",
    "\n",
    "**TODO:** \n",
    "\n",
    "Fix from here\n",
    "\n",
    "**Linear Univariate Model:**\n",
    "\n",
    "A t-statistic can be constructed to test $\\beta_1 = c$ vs. $\\beta_1 \\neq c$\n",
    "\n",
    "The following statistic has a Student t-distribution with $n-2$ degrees of freedom:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl} t &=& \\frac{ b_1 - \\beta_1 }{ s_e / s_xx^{1/2} } \\\\ s_{xx} &=& \\sum \\left( x_i - \\overline{x} \\right)^2 \\end{array}\n",
    "$$\n",
    "\n",
    "and insert $\\beta_1 = c$.\n",
    "\n",
    "If you insert $c = 0$ and square the result you get the F-statistic from the ANOVA table.\n",
    "\n",
    "This t-variate can be used to form confidence intervals on the slope parameter.\n",
    "\n",
    "Following Chapter 2.4: limits for $\\beta_1$ are\n",
    "\n",
    "$$\n",
    "b_1 - t_{\\alpha / 2} \\frac{s_e}{s_{xx}^{1/2}} \\leq \\beta_1 \\leq b_1 + t_{\\alpha / 2} \\frac{s_e}{s_{xx}^{1/2}}\n",
    "$$\n",
    "\n",
    "where $t_{\\alpha / 2}$ is a $100(\\alpha / 2)%$ upper-tail t critical value with n-2 degrees of freedom\n",
    "\n",
    "Small model standard deviations will lead to small confidence intervals\n",
    "\n",
    "For the intercept parameter \\beta_0, use the following t-variate:\n",
    "\n",
    "$$\n",
    "t = \\frac{ b_0 - \\beta_0 }{ s_e \\left( n^{-1} + \\overline{x}^2 / s_{xx} \\right)^2 }\n",
    "$$\n",
    "\n",
    "**Multiple Linear Model:**\n",
    "\n",
    "Testing hypotheses on individual regression coefficients is of primary interest to someone performing regression analysis\n",
    "\n",
    "The t-statistic can be constructed to test $\\beta_j = c$ versus $\\beta_j \\neq c$.\n",
    "\n",
    "Test statistic used for this purpose is:\n",
    "\n",
    "$$\n",
    "t = \\frac{ b_j - c }{ s_e c_{jj}^{1/2} }\n",
    "$$\n",
    "\n",
    "where $s_e = (MSE)^{1/2}$ is the estimated error standard deviation.\n",
    "\n",
    "$$\n",
    "c_{jj} = \\left[ (n - 1) s_j^2 (1 - R_j^2) \\right]^{-1}\n",
    "$$\n",
    "\n",
    "$s_j^2$ is the sample variance of the n values of the jth predictor variable\n",
    "\n",
    "$R_j^2$ is the coefficient of determination for regression of $x_j$ on the constant term and the other $p-1$ predictor variables.\n",
    "\n",
    "Using t-statistics with $c = 0$ can be used to test statistical significance of of individual model parameters (usefulness of $x_j$ as predictor of response variable)\n",
    "\n",
    "NOTE: this test is only conditional, since $\\beta_j$ is partial regression coefficient, and $b_j$, $c_{jj}$ are functions of other predictor variable values\n",
    "\n",
    "Only determines significance of jth predictor variable conditional on the presence of the other predictor variables\n",
    "\n",
    "e.g. \"Each individual predictor variable contributes significantly to the given fits, given that the other two predictor variables are also included in the model\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Confidence Intervals\n",
    "\n",
    "Want confidence intervals for the response model $\\hat{y}$.\n",
    "\n",
    "**Linear Univariate Models:**\n",
    "\n",
    "Confidence interval constructed for the response model:\n",
    "\n",
    "$$\n",
    "\\mu = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "\n",
    "Mason: for fixed values of x...???\n",
    "\n",
    "The predicted response $\\hat{y}$ has a normal distribution (given certain assumptions).\n",
    "\n",
    "Thus mean and deviation given by:\n",
    "\n",
    "$$\n",
    "\\mu = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma \\left[ a_1 + \\left( x - a_2 \\right)^2 / s_{xx} \\right]^{1/2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "a_1 = \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_2 = \\overline{x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "s_{xx} = \\sum \\left( x_i - \\overline{x} \\right)^2\n",
    "$$\n",
    "\n",
    "And the following t-variate can be used to construct confidence intervals for $\\mu$:\n",
    "\n",
    "$$\n",
    "t = \\frac{ \\hat{y} - \\mu }{ s_e \\left( a_1 + \\left( x - a_2 \\right) / s_{xx} \\right)^2 }\n",
    "$$\n",
    "\n",
    "To form prediction interval for actual future response, not expected value of a response.\n",
    "\n",
    "Use this equation again, but replace $\\mu$ with $y_f$, and $a_1$ with $a_1 + 1$.\n",
    "\n",
    "$y_f$  is the future response\n",
    "\n",
    "$\\hat{y}$ is the predicted value of future response\n",
    "\n",
    "$a \\rightarrow a+1$ is because future response has standard deviation $\\sigma$ with an added variability\n",
    "\n",
    "Standard deviation of $\\hat{y} - y_f$ is:\n",
    "\n",
    "$$\n",
    "\\sigma = \\left( 1 + a_1 + \\left( x - a_2 \\right)^2 / s_{xx} \\right)^{1/2}\n",
    "$$\n",
    "\n",
    "**Multiple Linear Model:**\n",
    "\n",
    "Confidence interval for regression coefficients of multiple linear model:\n",
    "\n",
    "A $100(1-\\alpha)%$ confidence interval for $\\beta_j$ is given by:\n",
    "\n",
    "$$\n",
    "b_j - t_{\\alpha/2} s_e c_{jj}^{1/2} \\leq \\beta_j \\leq b_j + t_{\\alpha/2} s_e c_{jj}^{1/2}\n",
    "$$\n",
    "\n",
    "where $t_{\\alpha/2}$ is two-tailed $100 \\alpha %$ t critical value having $n - p - 1$ degrees of freedom.\n",
    "\n",
    "Simultaneous confidence intervals for all coefficients in multiple linear regression model cannot be computed using individual coefficient intervals.\n",
    "\n",
    "They ignore systematic variation of predictor variables and consequent correlation among coefficient estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Coefficient (R Squared)\n",
    "\n",
    "Measure of correlation between observed and predicted responses\n",
    "\n",
    "Univariate Linear Model\n",
    "\n",
    "$$\n",
    "R^2 = \\left[ corr(y,\\hat{y}) \\right]^2 = 1 - \\frac{SSE}{TSS}\n",
    "$$\n",
    "\n",
    "**Multiple Linear Model:**\n",
    "\n",
    "R-squared can be calculated as:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{SSE}{TSS}\n",
    "$$\n",
    "\n",
    "It should be acknowledged that as the number of predictor variables approaches the number of observations, this can become arbitrarily close to 1\n",
    "\n",
    "if $n = p+1$ then $R^2 = 1$.\n",
    "\n",
    "Adjusted $R^2$, denoted $R_a^2$:\n",
    "\n",
    "$$\n",
    "R_a^2 = 1 - a \\frac{SSE}{TSS}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "a = \\frac{ n-1 }{ n - p - 1 }\n",
    "$$\n",
    "\n",
    "Differences between $R^2$ and $R_a^2$ are minor except for when $n$ and $p$ are close.\n",
    "\n",
    "Caution should be used in relying on single measure of fit (e.g. $R^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Plots\n",
    "\n",
    "Contour plots can be used to determine sensitivities: if the response $y$ changes significantly in one parameter direction, it is sensitive to that parameter. If the contour shows a structure that is uniform in one parameter direction, the response is not sensitive to that parameter.\n",
    "\n",
    "For multiple responses, a contour plot for each response can be made, infeasible regions shaded gray, and the plots overlaid to yield the feasible region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determination of Outlier Data Points\n",
    "\n",
    "Mason Ch. 18\n",
    "\n",
    "Various test for outliers (p. 629, 631, etc.)\n",
    "\n",
    "Tests for response variable outliers\n",
    "\n",
    "Tests for predictor variable outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Things to Look At\n",
    "\n",
    "* Correlation between input variables - e.g., for time and temperature: $\\{t, T, tT, t^2, T^2\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues\n",
    "\n",
    "## Importance of Interaction Terms\n",
    "\n",
    "We mentioned above that screening and highly fractionated factorial designs tend to ignore interaction effects by aliasing them with main effects.\n",
    "\n",
    "This important note from Mason indicates that this can be avoided by only including the colinear interaction terms that are most likely to be significant:\n",
    "\n",
    "<blockquote>\n",
    "Ordinarily, one should not routinely insert products of all the predictors in a regression model. To do so might create unnecessary complications in the analysis and interpretation of the fitted models due to collinear predictor variables. The purpose of including interaction terms in regression models is to improve the fit either because theoretical considerations require a modeling of the joint effects or because an analysis of the regression data indicates that joint effects are needed in addition to the linear terms of the individual variables.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Multimodal Variables\n",
    "\n",
    "Sometimes, when constructing response surfaces, modal variables appear. Modal variables are variables that have multiple modes, or distinct sets of values. There are two variations of modal variables:\n",
    "\n",
    "* One uncertainty range\n",
    "* N uncertainty range\n",
    "\n",
    "### One Uncertainty Range\n",
    "\n",
    "These types of modal variables have a single range of uncertainty assigned to them, but the values within that range of uncertainty are discrete. In order to sample the parameter within the range of uncertainty, the parameter must be sampled at distinct, discrete values.\n",
    "\n",
    "For example, if I am using the discrete ordinates model (DOM) for radiation calculations, the DOM requires a number of ordinate directions. This is a discrete value with distinct sets of values - e.g. 3, 6, 8, 24, etc.\n",
    "\n",
    "Each discrete value in this case composes a single range of uncertainty. Using the DOM example, that range of uncertainty would be $[3, 24]$.\n",
    "\n",
    "### N Uncertainty Ranges\n",
    "\n",
    "The other type of modal variables have several ranges of uncertainty assigned to them, with no restriction on values within that range of uncertainty being discrete or distinct. Essentially this can be thought of as a bimodal uncertainty distribution, where the two modes are distinct. Each mode can be sampled as usual, the only sticking point is that there is more than 1, and that they are distinct.\n",
    "\n",
    "The case of mixing in a chemically reacting system provides an example of how to think about this. Suppose we are investigating two mass flowrates of material into a reactor where there is mixing occurring - mass flowrates of 1 kg/s and 2 kg/s. \n",
    "\n",
    "Each mode also has a range of uncertainty. This can be an absolute range (as in, $\\pm 0.1$ kg/s) or a relative range (as in, $\\pm 5 \\%$).\n",
    "\n",
    "### How To Deal\n",
    "\n",
    "Multimodal variables can be dealt with in two ways:\n",
    "\n",
    "**Method 1: Separate Response Surfaces for Each Mode**\n",
    "\n",
    "The first way is to create a separate response surface for each distinct mode. This method works for both types of modal variables (1 uncertainty range represented by N distinct values, and N uncertainty ranges). This method is illustrated in the figures below. Each distinct mode (gray region) has its own computed response surface (blue dotted line), distinct from the response surface of the other modes.\n",
    "\n",
    "Of course, if the variable type is 1 uncertainty range represented by N distinct values, then there is no uncertainty range for each mode, and each gray region is, in fact, a delta function. As mentioned above, this means that the input variable is eliminated as a response surface parameter.\n",
    "\n",
    "If the variable type is N uncertainty ranges, then each uncertainty range is sampled as usual, and each response surface is constructed as usual. \n",
    "\n",
    "**Method 2: Single Response Surface (Ignore Modes)**\n",
    "\n",
    "A second way is to create a single response surface. This is typically only possible with N uncertainty ranges type of problems, because the parameter value is continuous, but it is only certain regions that are of interest. This approach is illustrated below.\n",
    "\n",
    "Essentially, this approach does away with any special treatment of modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
